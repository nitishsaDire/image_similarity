{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61316455-fadb-4e34-b398-fa553619169e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40d4f4ca-86ac-49fc-9af7-a104e7fc28c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import torch\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "def get_mnist(split_type):\n",
    "\ttfs = transforms.ToTensor()\n",
    "\tif split_type == 'train':\n",
    "\t\tds = datasets.MNIST(root='data', train=True, transform=tfs, download=True)\n",
    "\telse:\n",
    "\t\tds = datasets.MNIST(root='data', train=False, transform=tfs)\n",
    "\treturn ds\n",
    "\n",
    "\n",
    "class MNIST_triplet_Dataset(Dataset):\n",
    "\tdef __init__(self, split_type=\"train\", augment=False, img_width=128, img_height=128, is_triplet_ds=True):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.split_type = split_type\n",
    "\t\tself.august = augment\n",
    "\t\tself.img_width = img_width\n",
    "\t\tself.img_height = img_height\n",
    "\t\tself.is_triplet_ds=is_triplet_ds\n",
    "\t\tself.ds = get_mnist(self.split_type)\n",
    "\t\tif self.is_triplet_ds:\n",
    "\t\t\tself.setup()\n",
    "\t\t\tself.generate_triplets()\n",
    "\n",
    "\n",
    "\tdef setup(self):\n",
    "\t\tidx2class={idx:x[1] for idx, x in enumerate(self.ds)}\n",
    "\t\tself.class_indices={i:[] for i in range(10)}\n",
    "\t\t[self.class_indices[v].append(k) for k,v in idx2class.items()]\n",
    "\n",
    "\n",
    "\tdef generate_triplets(self):\n",
    "\t\tself.triplets=[]\n",
    "\t\tprint(f\"len of dataset for split={self.split_type} is {len(self.ds)}\")\n",
    "\t\tfor idx, v in tqdm(enumerate(self.ds)):\n",
    "\t\t\tp_idx=random.sample(self.class_indices[v[1]],1)[0]\n",
    "\t\t\tn_cls=random.sample(set(range(10)).difference([v[1]]), 1)[0]\n",
    "\t\t\tn_idx=random.sample(self.class_indices[n_cls],1)[0]\n",
    "\t\t\ta=torch.repeat_interleave(v[0],3,0)\n",
    "\t\t\tp=torch.repeat_interleave(self.ds[p_idx][0],3,0)\n",
    "\t\t\tn=torch.repeat_interleave(self.ds[n_idx][0],3,0)\n",
    "\t\t\tself.triplets.append([a, p, n, v[1], n_cls])\n",
    "\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\tif self.is_triplet_ds:\n",
    "\t\t\treturn self.triplets[index]\n",
    "\t\telse:\n",
    "\t\t\treturn torch.repeat_interleave(self.ds[index][0],3,0), self.ds[index][1]\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\tif self.is_triplet_ds:\n",
    "\t\t\treturn len(self.triplets)\n",
    "\t\telse:\n",
    "\t\t\treturn len(self.ds)\n",
    "\n",
    "\n",
    "def get_dataloader(bs, is_triplet_ds=True):\n",
    "\ttrain_ds, val_ds=get_dataset(is_triplet_ds=is_triplet_ds)\n",
    "\n",
    "\ttrain_dl = DataLoader(dataset=train_ds, batch_size=bs)\n",
    "\tval_dl = DataLoader(dataset=val_ds, batch_size=bs)\n",
    "\treturn train_dl, val_dl\n",
    "\n",
    "\n",
    "def get_dataset(is_triplet_ds=True):\n",
    "\ttrain_ds=MNIST_triplet_Dataset('train', is_triplet_ds=is_triplet_ds)\n",
    "\tval_ds=MNIST_triplet_Dataset('valid', is_triplet_ds=is_triplet_ds)\n",
    "\treturn train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c85e61a8-6bac-4053-a8b2-1b736e754243",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = get_dataset(is_triplet_ds=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "483e2732-cf29-4e6c-bb68-82f6f692b72e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 5)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a09cda48-ad91-49ab-acf6-5360fa5ef9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx=[5239]\n",
    "for i in idx:\n",
    "    a,p,n,p_cls,n_cls=mtd[i]\n",
    "    fig, axs = plt.subplots(1, 3)\n",
    "    \n",
    "    axs[0].imshow(a[0], cmap='Greys')\n",
    "    axs[1].imshow(p[0], cmap='Greys')\n",
    "    axs[2].imshow(n[0], cmap='Greys')\n",
    "    print(p_cls, n_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21166d62-b2fc-4ed9-8638-02929f4532c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7442889135537482 True\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "r=random.random()\n",
    "print(r, r>0.1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf925a32-2722-473b-8046-00d3d618f6cc",
   "metadata": {},
   "source": [
    "p_cls, n_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7f8f133-7acf-4c68-acdc-77f3707a934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from torchvision.models import efficientnet_b0, efficientnet_b4\n",
    "\n",
    "\n",
    "class EFFB0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        use_cuda = torch.cuda.is_available()  # check if GPU exists\n",
    "        self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")  # use CPU or GPU\n",
    "\n",
    "        eff_b0 = efficientnet_b0(pretrained=True)\n",
    "        self.seq=nn.Sequential(*list(eff_b0.children())[:-1])\n",
    "        \n",
    "        self.linear0=nn.Linear(in_features=1280, out_features=1024, bias=True).to(self.device)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.seq(x).squeeze(-1).squeeze(-1)\n",
    "        embedding=self.linear0(x)\n",
    "        return (embedding)\n",
    "\n",
    "class EFFB4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        use_cuda = torch.cuda.is_available()  # check if GPU exists\n",
    "        self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")  # use CPU or GPU\n",
    "\n",
    "        eff_b0 = efficientnet_b4(pretrained=True)\n",
    "        self.seq=nn.Sequential(*list(eff_b0.children())[:-1])\n",
    "        \n",
    "        self.linear0=nn.Linear(in_features=1792, out_features=1024, bias=True).to(self.device)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.seq(x).squeeze(-1).squeeze(-1)\n",
    "        embedding=self.linear0(x)\n",
    "        return (embedding)\n",
    "\n",
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01d1bb50-f48f-4976-8e6b-205da5189e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EFFB4().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5f7c734-c565-4476-9b8d-9663236c50c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1024])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(3,3,28,28)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "787e6098-45a6-44d1-8a14-de2e29fda0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_single_ds, val_single_ds = get_dataloader(bs=32, is_triplet_ds=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdbaffde-0fe9-4a9d-bca0-68f834c6c824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/tmp/ipykernel_115300/3677277827.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  feature = model(torch.tensor(X).to(device).float())\n",
      "10it [00:01,  6.73it/s]\n"
     ]
    }
   ],
   "source": [
    "features=[]\n",
    "ids=[]\n",
    "with torch.no_grad():\n",
    "    for idx, i in tqdm(enumerate(train_single_ds)):\n",
    "        X,id=i[0], i[1]\n",
    "        feature = model(torch.tensor(X).to(device).float())\n",
    "        features.append(feature)\n",
    "        ids.append(id)\n",
    "        if idx==10:\n",
    "            break\n",
    "# breakpoint()\n",
    "# features=torch.stack(features).view(-1, 1024)\n",
    "# ids=torch.stack(ids).view(-1).cpu().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12bc05c3-3165-4b83-8377-eab4efa1bb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, torch.Size([32, 1024]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features), features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fc758b7-bd7a-4b58-ab1e-66437e237a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([352, 1024])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.concat(features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cb6d785-553f-47ff-a4a5-8f94f596c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=torch.repeat_interleave(features,100,0 ).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e137e8f-67bb-48c5-92dc-a79080ed53af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35200, 1024)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09c372e3-1549-458c-8e7b-06754af314f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñç                                      | 400/35200 [00:04<06:59, 83.05it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 401 is out of bounds for axis 0 with size 352",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_110673/1492170366.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msimilar_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msimilar_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msimilar_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilar_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_110673/1492170366.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msimilar_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msimilar_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msimilar_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilar_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 401 is out of bounds for axis 0 with size 352"
     ]
    }
   ],
   "source": [
    "index = faiss.IndexFlatL2(features.shape[1])\n",
    "index.add(features)\n",
    "preds=[]\n",
    "for feature in tqdm(features):\n",
    "    similar_indices=index.search(feature.reshape(1,-1), 6)[1][0][1:]\n",
    "    similar_ids=[ids[idx] for idx in similar_indices]\n",
    "    preds.append(similar_ids)\n",
    "preds=np.array(preds)\n",
    "gt=np.array(ids).reshape(-1,1)\n",
    "del index\n",
    "acc=accuracy_score(gt[:,0], preds[:,0])\n",
    "\n",
    "print(f'acc {data}: {acc}')\n",
    "print(f'MAP@1 {data}: {calculate_map_at_k(gt, preds, 1)}')\n",
    "print(f'MAP@3 {data}: {calculate_map_at_k(gt, preds, 3)}')\n",
    "print(f'MAP@5 {data}: {calculate_map_at_k(gt, preds, 5)}')\n",
    "return calculate_map_at_k(gt, preds, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e32e825-4a83-4b83-8ed3-37359f314007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e1b86b-92af-48e5-b6b4-32dcff4ab151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "047f56a7-3189-451a-a669-083d3f7586a6",
   "metadata": {},
   "source": [
    "## triplet loss implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c864b18f-2df3-4bca-9a57-e19ac8f30dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "eps = 1e-8 # an arbitrary small value to be used for numerical stability tricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53b1772f-7d6a-43f5-9d75-b3674d910b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()  # check if GPU exists\n",
    "device = \"cuda\" if use_cuda else \"cpu\"  # use CPU or GPU\n",
    "\n",
    "eps = 1e-8 # an arbitrary small value to be used for numerical stability tricks\n",
    "\n",
    "def euclidean_distance_matrix(x):\n",
    "  \"\"\"Efficient computation of Euclidean distance matrix\n",
    "\n",
    "  Args:\n",
    "    x: Input tensor of shape (batch_size, embedding_dim)\n",
    "    \n",
    "  Returns:\n",
    "    Distance matrix of shape (batch_size, batch_size)\n",
    "  \"\"\"\n",
    "  # step 1 - compute the dot product\n",
    "\n",
    "  # shape: (batch_size, batch_size)\n",
    "  dot_product = torch.mm(x, x.t())\n",
    "\n",
    "  # step 2 - extract the squared Euclidean norm from the diagonal\n",
    "\n",
    "  # shape: (batch_size,)\n",
    "  squared_norm = torch.diag(dot_product)\n",
    "\n",
    "  # step 3 - compute squared Euclidean distances\n",
    "\n",
    "  # shape: (batch_size, batch_size)\n",
    "  distance_matrix = squared_norm.unsqueeze(0) - 2 * dot_product + squared_norm.unsqueeze(1)\n",
    "\n",
    "  # get rid of negative distances due to numerical instabilities\n",
    "  distance_matrix = F.relu(distance_matrix)\n",
    "\n",
    "  # step 4 - compute the non-squared distances\n",
    "  \n",
    "  # handle numerical stability\n",
    "  # derivative of the square root operation applied to 0 is infinite\n",
    "  # we need to handle by setting any 0 to eps\n",
    "  mask = (distance_matrix == 0.0).float()\n",
    "\n",
    "  # use this mask to set indices with a value of 0 to eps\n",
    "  distance_matrix =distance_matrix.clone() + mask * eps\n",
    "\n",
    "  # now it is safe to get the square root\n",
    "  distance_matrix = torch.sqrt(distance_matrix.clone())\n",
    "\n",
    "  # undo the trick for numerical stability\n",
    "  distance_matrix = distance_matrix.clone() * (1.0 - mask)\n",
    "\n",
    "  return distance_matrix\n",
    "\n",
    "\n",
    "def get_triplet_mask(labels):\n",
    "  \"\"\"compute a mask for valid triplets\n",
    "\n",
    "  Args:\n",
    "    labels: Batch of integer labels. shape: (batch_size,)\n",
    "\n",
    "  Returns:\n",
    "    Mask tensor to indicate which triplets are actually valid. Shape: (batch_size, batch_size, batch_size)\n",
    "    A triplet is valid if:\n",
    "    `labels[i] == labels[j] and labels[i] != labels[k]`\n",
    "    and `i`, `j`, `k` are different.\n",
    "  \"\"\"\n",
    "  # step 1 - get a mask for distinct indices\n",
    "\n",
    "  # shape: (batch_size, batch_size)\n",
    "  indices_equal = torch.eye(labels.size()[0], dtype=torch.bool, device=labels.device)\n",
    "  indices_not_equal = torch.logical_not(indices_equal)\n",
    "  # shape: (batch_size, batch_size, 1)\n",
    "  i_not_equal_j = indices_not_equal.unsqueeze(2)\n",
    "  # shape: (batch_size, 1, batch_size)\n",
    "  i_not_equal_k = indices_not_equal.unsqueeze(1)\n",
    "  # shape: (1, batch_size, batch_size)\n",
    "  j_not_equal_k = indices_not_equal.unsqueeze(0)\n",
    "  # Shape: (batch_size, batch_size, batch_size)\n",
    "  distinct_indices = torch.logical_and(torch.logical_and(i_not_equal_j, i_not_equal_k), j_not_equal_k)\n",
    "\n",
    "  # step 2 - get a mask for valid anchor-positive-negative triplets\n",
    "\n",
    "  # shape: (batch_size, batch_size)\n",
    "  labels_equal = labels.unsqueeze(0) == labels.unsqueeze(1)\n",
    "  # shape: (batch_size, batch_size, 1)\n",
    "  i_equal_j = labels_equal.unsqueeze(2)\n",
    "  # shape: (batch_size, 1, batch_size)\n",
    "  i_equal_k = labels_equal.unsqueeze(1)\n",
    "  # shape: (batch_size, batch_size, batch_size)\n",
    "  valid_indices = torch.logical_and(i_equal_j, torch.logical_not(i_equal_k))\n",
    "\n",
    "  # step 3 - combine two masks\n",
    "  mask = torch.logical_and(distinct_indices, valid_indices)\n",
    "\n",
    "  return mask\n",
    "\n",
    "\n",
    "class BatchAllTtripletLoss(nn.Module):\n",
    "  \"\"\"Uses all valid triplets to compute Triplet loss\n",
    "\n",
    "  Args:\n",
    "    margin: Margin value in the Triplet Loss equation\n",
    "  \"\"\"\n",
    "  def __init__(self, margin=1., hard_mining=False):\n",
    "    super().__init__()\n",
    "    self.margin = margin\n",
    "    self.hard_mining = hard_mining\n",
    "    \n",
    "  def forward(self, embeddings, labels):\n",
    "    \"\"\"computes loss value.\n",
    "\n",
    "    Args:\n",
    "      embeddings: Batch of embeddings, e.g., output of the encoder. shape: (batch_size, embedding_dim)\n",
    "      labels: Batch of integer labels associated with embeddings. shape: (batch_size,)\n",
    "\n",
    "    Returns:\n",
    "      Scalar loss value.\n",
    "    \"\"\"\n",
    "    # step 1 - get distance matrix\n",
    "    # shape: (batch_size, batch_size)\n",
    "    distance_matrix = euclidean_distance_matrix(embeddings)\n",
    "\n",
    "    # step 2 - compute loss values for all triplets by applying broadcasting to distance matrix\n",
    "\n",
    "    # shape: (batch_size, batch_size, 1)\n",
    "    anchor_positive_dists = distance_matrix.unsqueeze(2)\n",
    "    # shape: (batch_size, 1, batch_size)\n",
    "    anchor_negative_dists = distance_matrix.unsqueeze(1)\n",
    "    # get loss values for all possible n^3 triplets\n",
    "    # shape: (batch_size, batch_size, batch_size)\n",
    "    triplet_loss = anchor_positive_dists - anchor_negative_dists + self.margin\n",
    "\n",
    "    # step 3 - filter out invalid or easy triplets by setting their loss values to 0\n",
    "\n",
    "    # shape: (batch_size, batch_size, batch_size)\n",
    "    mask = get_triplet_mask(labels).to(device)\n",
    "    triplet_loss *= mask\n",
    "    # easy triplets have negative loss values\n",
    "    triplet_loss = F.relu(triplet_loss)\n",
    "\n",
    "    # step 4 - compute scalar loss value by averaging positive losses\n",
    "    num_positive_losses = (triplet_loss > eps).float().sum()\n",
    "    triplet_loss = triplet_loss.sum() / (num_positive_losses + eps)\n",
    "\n",
    "    return triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c00e6e8-f540-4ca7-9a7b-03c6b9c64f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb  torch.Size([8, 128])\n",
      "distance  torch.Size([8, 8])\n",
      "labels  torch.Size([8])\n",
      "triplet loss value is 1.1317579746246338\n"
     ]
    }
   ],
   "source": [
    "bs=8\n",
    "emb_dim=128\n",
    "C=10\n",
    "embeddings=torch.randn(bs,emb_dim)\n",
    "print(\"emb \", embeddings.shape)\n",
    "distance=euclidean_distance_matrix(embeddings)\n",
    "print(\"distance \", distance.shape)\n",
    "labels=torch.randint(0, C, (bs,))\n",
    "print(\"labels \", labels.shape)\n",
    "\n",
    "triplet_loss=BatchAllTtripletLoss()\n",
    "\n",
    "loss=triplet_loss(embeddings, labels)\n",
    "print(f'triplet loss value is {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb08d172-3b26-4b9b-bc87-9b319d4d0531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 4, 7, 5, 5, 3, 4, 5])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f9b4789-2d13-483d-b2b6-e54362da8bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=get_triplet_mask(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8c2f57b-3586-48e2-928e-1b8adc104d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10, 10])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85dcd87c-6bce-4cd2-80c5-d3876bc0b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BatchAllTripletLoss(nn.Module):\n",
    "    \"\"\"Triplet loss with optional hard mining.\"\"\"\n",
    "    def __init__(self, margin=1.0, hard_mining=False):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "        self.hard_mining = hard_mining\n",
    "\n",
    "    def forward(self, embeddings, labels):\n",
    "        distance_matrix = euclidean_distance_matrix(embeddings)\n",
    "\n",
    "        if self.hard_mining:\n",
    "            return self.hard_mining_loss(distance_matrix, labels)\n",
    "        else:\n",
    "            return self.batch_all_loss(distance_matrix, labels)\n",
    "\n",
    "    def batch_all_loss(self, distance_matrix, labels):\n",
    "        anchor_positive_dists = distance_matrix.unsqueeze(2)\n",
    "        anchor_negative_dists = distance_matrix.unsqueeze(1)\n",
    "        triplet_loss = anchor_positive_dists - anchor_negative_dists + self.margin\n",
    "\n",
    "        mask = get_triplet_mask(labels).to(device)\n",
    "        triplet_loss *= mask\n",
    "        triplet_loss = F.relu(triplet_loss)\n",
    "\n",
    "        num_positive_losses = (triplet_loss > eps).float().sum()\n",
    "        triplet_loss = triplet_loss.sum() / (num_positive_losses + eps)\n",
    "        return triplet_loss\n",
    "\n",
    "    def hard_mining_loss(self, distance_matrix, labels):\n",
    "        batch_size = labels.size(0)\n",
    "        triplet_loss = 0.0\n",
    "        valid_triplets = 0\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            anchor_label = labels[i]\n",
    "\n",
    "            # Mask for positive samples\n",
    "            positive_mask = (labels == anchor_label).float()\n",
    "            positive_mask[i] = 0  # Exclude the anchor itself\n",
    "\n",
    "            # Mask for negative samples\n",
    "            negative_mask = (labels != anchor_label).float()\n",
    "\n",
    "            # Select hardest positive (max distance)\n",
    "            hardest_positive_dist = (distance_matrix[i] * positive_mask).max()\n",
    "\n",
    "            # Select hardest negative (min distance)\n",
    "            hardest_negative_dist = (distance_matrix[i] + (1.0 - negative_mask) * 1e6).min()\n",
    "\n",
    "            # Compute triplet loss for this anchor\n",
    "            loss = F.relu(hardest_positive_dist - hardest_negative_dist + self.margin)\n",
    "\n",
    "            if loss > 0:\n",
    "                triplet_loss += loss\n",
    "                valid_triplets += 1\n",
    "\n",
    "        # Average over valid triplets\n",
    "        triplet_loss /= (valid_triplets + eps)\n",
    "        return triplet_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "81c00721-3b1d-4e2b-8d00-d045e35918b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_example_mining(dist_mat, labels, return_inds=False):\n",
    "    \"\"\"For each anchor, find the hardest positive and negative sample.\n",
    "    Args:\n",
    "      dist_mat: pytorch Variable, pair wise distance between samples, shape [N, N]\n",
    "      labels: pytorch LongTensor, with shape [N]\n",
    "      return_inds: whether to return the indices. Save time if `False`(?)\n",
    "    Returns:\n",
    "      dist_ap: pytorch Variable, distance(anchor, positive); shape [N]\n",
    "      dist_an: pytorch Variable, distance(anchor, negative); shape [N]\n",
    "      p_inds: pytorch LongTensor, with shape [N];\n",
    "        indices of selected hard positive samples; 0 <= p_inds[i] <= N - 1\n",
    "      n_inds: pytorch LongTensor, with shape [N];\n",
    "        indices of selected hard negative samples; 0 <= n_inds[i] <= N - 1\n",
    "    NOTE: Only consider the case in which all labels have same num of samples,\n",
    "      thus we can cope with all anchors in parallel.\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(dist_mat.size()) == 2\n",
    "    assert dist_mat.size(0) == dist_mat.size(1)\n",
    "    N = dist_mat.size(0)\n",
    "\n",
    "    # shape [N, N]\n",
    "    is_pos = labels.expand(N, N).eq(labels.expand(N, N).t())\n",
    "    is_neg = labels.expand(N, N).ne(labels.expand(N, N).t())\n",
    "\n",
    "    # `dist_ap` means distance(anchor, positive)\n",
    "    # both `dist_ap` and `relative_p_inds` with shape [N, 1]\n",
    "    dist_ap, relative_p_inds = torch.max(\n",
    "        (dist_mat * is_pos.float()).contiguous().view(N, -1), 1, keepdim=True)\n",
    "    # `dist_an` means distance(anchor, negative)\n",
    "    # both `dist_an` and `relative_n_inds` with shape [N, 1]\n",
    "    temp = dist_mat * is_neg.float()\n",
    "    temp[temp == 0] = 10e5\n",
    "    dist_an, relative_n_inds = torch.min(\n",
    "        (temp).contiguous().view(N, -1), 1, keepdim=True)\n",
    "    # shape [N]\n",
    "    dist_ap = dist_ap.squeeze(1)\n",
    "    dist_an = dist_an.squeeze(1)\n",
    "\n",
    "    return dist_ap, dist_an\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c94120e5-e008-47fa-80a3-da21e9cbd9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb  torch.Size([4, 128])\n",
      "distance  torch.Size([4, 4])\n",
      "labels  torch.Size([4])\n",
      "triplet loss value is 1.3609514236450195 and with hm loss is 1.3609514236450195\n",
      "hm loss = 1.5694499015808105\n"
     ]
    }
   ],
   "source": [
    "bs=4\n",
    "emb_dim=128\n",
    "C=2\n",
    "margin=0.2\n",
    "embeddings=torch.randn(bs,emb_dim)\n",
    "print(\"emb \", embeddings.shape)\n",
    "distance=euclidean_distance_matrix(embeddings)\n",
    "print(\"distance \", distance.shape)\n",
    "labels=torch.randint(0, C, (bs,))\n",
    "print(\"labels \", labels.shape)\n",
    "\n",
    "triplet_loss=BatchAllTtripletLoss(margin=0.2, hard_mining=False)\n",
    "triplet_loss_hm=BatchAllTtripletLoss(margin=0.2, hard_mining=True)\n",
    "\n",
    "loss=triplet_loss(embeddings, labels)\n",
    "loss_hm=triplet_loss_hm(embeddings, labels)\n",
    "print(f'triplet loss value is {loss} and with hm loss is {loss_hm}')\n",
    "\n",
    "ap, an=hard_example_mining(distance, labels)\n",
    "hm_loss = F.relu(ap - an + margin)\n",
    "hm_loss = hm_loss.sum()/(hm_loss>0).sum()\n",
    "print(f\"hm loss = {hm_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d1d040a9-fbda-4f2b-a32f-0c9185f3258b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0000, 16.5030, 15.8775, 14.6545],\n",
       "         [16.5030,  0.0000, 16.1076, 15.0407],\n",
       "         [15.8775, 16.1076,  0.0000, 15.3101],\n",
       "         [14.6545, 15.0407, 15.3101,  0.0000]]),\n",
       " tensor([1, 1, 1, 0]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e021fc-1f79-4355-a59c-5f6e1f547b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1b743874-5617-4168-8844-36b0df5f2da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = F.relu(ap - an + margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ead2c11a-6fd7-4316-bb46-45f22107b3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0485, 1.6623, 0.9975, 0.0000])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d897150d-b3cb-4e67-acfb-159aa782ba47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5694)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.sum()/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "16029ca1-f57a-4001-bf46-5959b76eb061",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat=distance.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "19de7690-c84f-4dcf-bf59-c05fda8f315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(dist_mat.size()) == 2\n",
    "assert dist_mat.size(0) == dist_mat.size(1)\n",
    "N = dist_mat.size(0)\n",
    "\n",
    "# shape [N, N]\n",
    "is_pos = labels.expand(N, N).eq(labels.expand(N, N).t())\n",
    "is_neg = labels.expand(N, N).ne(labels.expand(N, N).t())\n",
    "\n",
    "# `dist_ap` means distance(anchor, positive)\n",
    "# both `dist_ap` and `relative_p_inds` with shape [N, 1]\n",
    "dist_ap, relative_p_inds = torch.max(\n",
    "    (dist_mat * is_pos.float()).contiguous().view(N, -1), 1, keepdim=True)\n",
    "# `dist_an` means distance(anchor, negative)\n",
    "# both `dist_an` and `relative_n_inds` with shape [N, 1]\n",
    "temp = dist_mat * is_neg.float()\n",
    "temp[temp == 0] = 10e5\n",
    "dist_an, relative_n_inds = torch.min(\n",
    "    (temp).contiguous().view(N, -1), 1, keepdim=True)\n",
    "# shape [N]\n",
    "dist_ap = dist_ap.squeeze(1)\n",
    "dist_an = dist_an.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d0dba8a9-31f7-4510-8973-46c224858292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0000, 17.0293, 16.1232, 14.4503],\n",
       "         [17.0293,  0.0000, 16.9030, 16.3004],\n",
       "         [16.1232, 16.9030,  0.0000, 15.9929],\n",
       "         [14.4503, 16.3004, 15.9929,  0.0000]]),\n",
       " tensor([[ True,  True, False,  True],\n",
       "         [ True,  True, False,  True],\n",
       "         [False, False,  True, False],\n",
       "         [ True,  True, False,  True]]),\n",
       " tensor([[False, False,  True, False],\n",
       "         [False, False,  True, False],\n",
       "         [ True,  True, False,  True],\n",
       "         [False, False,  True, False]]),\n",
       " tensor([17.0293, 17.0293,  0.0000, 16.3004]),\n",
       " tensor([16.1232, 16.9030, 15.9929, 15.9929]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_mat, is_pos, is_neg, dist_ap, dist_an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c40d9c7b-a72b-4e74-9eb4-832f2a30c567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=2\n",
    "j=5\n",
    "k=8\n",
    "mask[i,j,k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "020e18aa-740e-4458-a57c-9dd61db0ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.randn(32,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "11805e1e-dfe6-4d81-9dd0-ab37721a4d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "90fbd84a-4094-4112-b4dd-06375768d6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x/x.norm(dim=0)).norm(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7a9318ed-2845-4487-8561-c4596152c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cifar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b2ce0b0c-c57c-49df-8ea0-473de06c0d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading cifar-10-python.tar.gz...\n",
      "Downloaded cifar-10-python.tar.gz to ./cifar-10-data/cifar-10-python.tar.gz\n",
      "Extracting cifar-10-python.tar.gz...\n",
      "Extracted to ./cifar-10-data\n",
      "Removed the downloaded file: ./cifar-10-data/cifar-10-python.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import tarfile\n",
    "\n",
    "def download_and_extract(url, extract_path):\n",
    "    \"\"\"\n",
    "    Downloads a gzipped tar file from the given URL and extracts it locally.\n",
    "    \n",
    "    Args:\n",
    "        url (str): URL to the gzipped tar file.\n",
    "        extract_path (str): Directory where the contents will be extracted.\n",
    "    \"\"\"\n",
    "    # Ensure the extraction directory exists\n",
    "    os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "    # Download the file\n",
    "    file_name = url.split(\"/\")[-1]\n",
    "    file_path = os.path.join(extract_path, file_name)\n",
    "    print(f\"Downloading {file_name}...\")\n",
    "    \n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        print(f\"Downloaded {file_name} to {file_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
    "        return\n",
    "\n",
    "    # Extract the file\n",
    "    print(f\"Extracting {file_name}...\")\n",
    "    if tarfile.is_tarfile(file_path):\n",
    "        with tarfile.open(file_path, \"r:gz\") as tar:\n",
    "            tar.extractall(path=extract_path)\n",
    "        print(f\"Extracted to {extract_path}\")\n",
    "    else:\n",
    "        print(f\"{file_path} is not a valid tar file.\")\n",
    "    \n",
    "    # Optionally, delete the tar file to save space\n",
    "    os.remove(file_path)\n",
    "    print(f\"Removed the downloaded file: {file_path}\")\n",
    "\n",
    "# URL of the CIFAR-10 dataset\n",
    "url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "\n",
    "# Path to extract the dataset\n",
    "extract_path = \"./cifar-10-data\"\n",
    "\n",
    "# Download and extract\n",
    "download_and_extract(url, extract_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "91e180ee-b4e8-4f3c-925d-ed974134a5f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_288273/2674167076.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils.np_utils import to_categorical   \n",
    "\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "168a2dec-d94d-4c72-b3a3-05124b7d33a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=unpickle('cifar-10-data/cifar-10-batches-py/data_batch_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ac021eb9-95c8-43cc-a358-a30af7986992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d233c5-ee27-423f-b83f-03250541c18d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
